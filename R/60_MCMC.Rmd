---
title: "MCMC"
author: "Nicholas Nagle"
date: "April 20, 2015"
output: pdf_document
---
```{r load data, echo=FALSE, message=FALSE, warning=FALSE, results='hide'}

#gc()
library(dplyr)
library(tidyr)
library(Matrix)
library(INLA)
library("mvtnorm")
library(abind)
library(splines)
library(ff)
options(fftempdir='/Users/nnagle/Dropbox/git_root/climate-bayes/R')

```


```{r, eval=TRUE}
ffload(file='/Users/nnagle/Dropbox/git_root/climate-bayes/R/mcout.ff', overwrite=TRUE)
```

```{r source thompson solver, eval=TRUE}
Rcpp::sourceCpp('~/Dropbox/git_root/climate-bayes/R/thompson_forward.cpp')
Rcpp::sourceCpp('~/Dropbox/git_root/climate-bayes/R/ridgeRegression.cpp')
#Rcpp::sourceCpp('~/Dropbox/git_root/climate-bayes/R/sim_rho_cpp.cpp')
```


```{r mcmc.updater, eval=TRUE}
mcmc.resize <- function(mc, N){
    out <- vector('list', length(mc))
    names(out) <- names(mc)
    for( o in 1:length(mc) ){
        obj = mc[[o]]
        if( class(obj) == 'matrix' ){
            out[[o]] <- rBind(obj, matrix(NA, N, dim(obj)[2]))
        } else if( class(obj) == 'array' ){
            out[[o]] <- abind(obj, array(NA, dim=c(N, dim(obj)[2], dim(obj)[3])), along=1)
        } else { stop('object not of matrix or array type') }
    }
    return(out)
}
```

```{r grow MC object, eval=TRUE}
#######################################################################
# Markov Chain Loop
sprintf('NMC = %s', 500)
start <- nrow(mc$theta)
mc <- mcmc.resize(mc, NMC)
# grow the mc save object
# grow the alpha ff object.  The only way I know to do this is to 
#  create a new one
old <- clone.ff(mc.X)
old.dims <- dim(mc.X)
mc.X <- ff(initdata=0.0, dim=old.dims+c(NMC,0,0))
mc.X[1:start,,] <- old[1:start,,]
rm(old, old.dims)

K0 <- .sparseDiagonal(n=Size, x=prior$sigma_sq_1)

measure <- measure %>% filter(year %in% years)
basis.map   <- basis.map[row.names(basis.map) %in% unique(measure$ID), ]
design  <- sparse.model.matrix(~species-1, data=measure)
row.names(design) <- measure$UID
site    <- site[site$ID %in% unique(measure$ID), ]
site$species <- factor(site$species, levels=levels(measure$species))



sites.by.years   <- split(measure$ID, measure$year)
uid.by.years    <- split(measure$UID, measure$year)
measure.by.years <- split(measure, measure$year)
design.by.years  <- lapply(uid.by.years, function(x) design[as.character(x),  ])
basis.by.years   <- lapply(sites.by.years, function(x) basis.map[x, ])
# Observation <- split(left_join(measure, site %>% mutate(row=1:nrow(site)) %>% .[['row']], measure$year)
# Observation <- lapply(Observation, function(x) sparseMatrix(i=1:length(x), j=x))

uid.by.species <- split(measure$UID, measure$species)
```

```{r, eval=TRUE}

# Last possible minute, create a rows.by.years lookup vector so we don't have to 
#  do character matching in the loop.
row.by.species <- split(1:nrow(measure), measure$species)
row.by.years <- split(1:nrow(measure), factor(measure$year, years))

state <- NULL
state$rho                  <- mc$rho[start]
state$theta                <- mc$theta[start,]
state$Q                    <- Q
state$sigma_sq_epsilon     <- mc$sigma_epsilon[start,]^2
state$sigma_sq_delta       <- mc$sigma_delta[start]^2
state$sigma.0              <- mc$sigma.0[start,]
state$sigma.1              <- mc$sigma.1[start,]
state$sigma.lat.0          <- mc$sigma.lat.0[start,]
state$sigma.lat.1          <- mc$sigma.lat.1[start,]
state$sigma.year.0         <- mc$sigma.year.0[start,]
state$sigma.year.1         <- mc$sigma.year.1[start,]

# Calculate beta_0 and beta_.1
# Create a new data.frame to store them in
iter.df <- measure %>% mutate(beta.0 = 0, beta.1=1)
tree.obs <- which(iter.df$species != 'INST')

for( s in 2:length(species_levels) ){
  alpha.0 <-c(mc$alpha.0[start, s, ], mc$alpha.lat.0[start,s, ],  mc$alpha.year.0[start,s ,])
  beta.0 <- fixed.design[[s]] %*% alpha.0 #create site.specific intercept
  iter.df$beta.0[row.by.species[[s]]] <- as.vector(beta.0)
  #NOTE: I just assumed that B had the same row ordering as row.by.species
  alpha.1 <-c(mc$alpha.1[start, s, ], mc$alpha.lat.1[start,s, ],  mc$alpha.year.1[start,s ,])
  beta.1 <- fixed.design[[s]] %*% alpha.1 #create site.specific slopes
  iter.df$beta.1[row.by.species[[s]]] <- as.vector(beta.1)
}
rm(s, alpha.0, beta.0, alpha.1, beta.1)

# Populate the data.frame with variance components
iter.df$sigma_sq_epsilon <- state$sigma_sq_epsilon[unclass(iter.df$species)]
#iter.df$sigma_sq_delta   <- iter.df$beta.1^2 * state$sigma_sq_delta
iter.df$sigma_sq_nu      <- iter.df$beta.1^2 * state$sigma_sq_delta + iter.df$sigma_sq_epsilon
iter.df$BX               <- 0

iter.df.by.years <- split(iter.df, factor(iter.df$year, years))
# Z_1 is beta1.basis
# multiply spatial basis by coefficient value
state$beta1.basis <- mapply(function(x,y) return( x * y$beta.1 ), basis.by.years, iter.df.by.years)

# inject temperature to data
X.to.df <- function(basis.by.years,X, rows.by.years){
  BX.hat <- mapply(function(b,x) b %*% x, basis.by.years,X)
  # Coerce the matrix into vector and inject into iter.df
  BX.hat <- do.call(c, lapply(BX.hat, as.vector))
  return(data_frame(ID=as.vector(do.call(c, row.by.years)), ba = BX.hat) %>%
    arrange(ID) %>% .[['ba']]  )
}

# log likelihood of MVN in canonical form:
#http://user.it.uu.se/~thosc112/pubpdf/schonl2011.pdf
ll_mvn_canonical <- function(x, Cinv, covector){
  N <- length(x)
  C <- Cholesky(Cinv)
  lognum <- -.5 * t(covector) %*% solve(C, covector)
  logden <- N/2 * log(2*pi) -  determinant(C, logarithm=TRUE)$modulus 
  # determinant of factor already returns half
  sse <- -.5* t(x) %*% Cinv %*% x + t(x) %*% covector
  return(as.numeric(lognum - logden + sse))
}

# log likelihood of Z given X
ll_Z_X <- function(df, col='BX'){
  resid <- df$prox - df$beta.0 - df$beta.1 * df[[col]]
  return( - .5 * sum(log(df$sigma_sq_nu)) - .5 * sum(resid^2/df$sigma_sq_nu) )
}

# log likelihood of X give rho and theta
ll_X_rho.theta <- function(X, rho, Q){
  N <- ncol(X)
  half.logdet <- .5*(N-1)*determinant(Q, logarithm=TRUE)$modulus
  sse <- sum(apply( X[,-1] - rho * X[,-N], 2, 
              function(x) as.numeric(t(x) %*% Q %*% x)))
  return( as.numeric(half.logdet - .5 * sse ) )
}

state_sim <- function(thompson, Q){
  N <- length(thompson$Lambda)
 # Evaluation simulation and smoothing
  X <- S <-  vector(mode='list', length=N)
  epsilon <- rnorm(n=nrow(Q))
  X[[N]] <- thompson$m[[N]] + backsolve(thompson$Lambda[[N]], epsilon, upper.tri=FALSE, transpose=TRUE)
  S[[N]] <- thompson$m[[N]]
  half.logdet <- sum(log(diag(thompson$Lambda[[N]])))
  sse <- as.numeric(t(X[[N]]-S[[N]]) %*% tcrossprod(thompson$Lambda[[N]]) %*% (X[[N]]-S[[N]]))
  for(t in seq(N-1, 1, -1)){
    epsilon <- epsilon2 <- rnorm(n=nrow(Q))
    epsilon <- epsilon - thompson$LambdaOmega[[t]] %*% X[[t+1]]
    X[[t]] <- thompson$m[[t]] + backsolve(thompson$Lambda[[t]], epsilon, 
                                          upper.tri=FALSE, transpose=TRUE)
    epsilon <-  - thompson$LambdaOmega[[t]] %*% S[[t+1]]
    S[[t]] <- thompson$m[[t]] + backsolve(thompson$Lambda[[t]], epsilon, 
                                          upper.tri=FALSE, transpose=TRUE)
    half.logdet <- half.logdet + as.numeric(sum(log(diag(thompson$Lambda[[t]]))))
    #sse <- sse + as.numeric(t(X[[t]]-S[[t]]) %*% tcrossprod(thompson$Lambda[[t]]) %*% (X[[t]]-S[[t]]))
    # That sse is incorrect b/c it doesn't include off diagonal components
  }
#  return(list(X=X, S=S, sse=sse, half.logdet=half.logdet))
  return(list(X=X, S=S,half.logdet=half.logdet))
}

precision_setup <- function(prior, state, Q, beta1.basis, iter.df.by.years){
  Size <- nrow(Q)
  # Calculate prior variance on X1
  P1 <- .sparseDiagonal(n=Size, x=prior$sigma_sq_1)
  P1inv <- .sparseDiagonal(n=Size, x=1/prior$sigma_sq_1)
  P1inv <- Q * (1-state$rho^2)
  # Calculate T * A_22 *T (refer to McCausland) # The variance due to
  #   carrying forward the previous state
  TA22T <- state$rho^2 * Q
  # Calculate the idiosyncratic precision of each obs
  #  This is the beta^2 * (field nugget) plus measurement error
  A11 <- lapply(iter.df.by.years, function(x) 1 / x$sigma_sq_nu)
  #A11 <- lapply(A11, function(x) {x[!is.finite(x)] <- 0; return(x)})
  A11 <- lapply(A11, function(x) .sparseDiagonal(n=length(x), x=x))

  Omega_tt <- vector(mode='list', length=N)
  Omega_tt[[1]] <- t(beta1.basis[[1]]) %*% A11[[1]] %*% beta1.basis[[1]] + TA22T + P1inv
  TA22TQ <- TA22T+Q
  for(t in 2:N){
    Omega_tt[[t]] <- t(beta1.basis[[t]]) %*% A11[[t]] %*% beta1.basis[[t]] + TA22TQ #time sink #2
  }
  Omega_tt[[N]] <- t(beta1.basis[[N]]) %*% A11[[N]] %*%  beta1.basis[[N]] + Q

  # Precompute Omega_t,t+t
  Omega_tt1 <- -state$rho * Q  #(it's the same for every time period)

  # Precompute c (McCausland eqn 15.)
  # Note: Z_11 is beta1.basis
  covec <- vector(mode='list', length=N)
  resid <- as.vector(iter.df$prox - iter.df$beta.0)
  for(t in 1:N){ 
    covec[[t]] <- t(beta1.basis[[t]]) %*% A11[[t]] %*% resid[row.by.years[[t]]]
  }
  return(list(Omega_tt=Omega_tt, Omega_tt1=Omega_tt1, covec=covec, P1inv=P1inv))
}


# Create state objects for adaptive sampling
state.rho <- list(sigma=.05, accept=0)
state.theta <- list(Sigma=diag(.08, 2), accept=0)
```

```{r, mcmc loop}

for(mciter in (start):(start+NMC-1)){
  # 1. Update rho
  ####################################################################
  # Using the technique in Mcausland
  
  # Evaluate current log likelihood
  prec <- precision_setup(prior, state, state$Q, state$beta1.basis, iter.df.by.years)
  thompson <- thompson_forward(prec$Omega_tt, lapply(prec$covec, as.matrix), as.matrix(prec$Omega_tt1))
  sim <- state_sim(thompson, Q = state$Q) 

  # Calculate log(f(Z | rho))
  iter.df$BS <- X.to.df(basis.by.years, sim$S, rows.by.years)
  S.mat <- as.matrix(do.call(cBind, sim$S))
  # f(Z|rho) = f(Z|X)f(X|rho, theta)
  ll_Z_rho <- ll_Z_X(iter.df, 'BS') + ll_X_rho.theta(S.mat, state$rho, state$Q) -
    .5* (t(S.mat[,1]) %*% prec$P1inv %*% S.mat[,1]) - 
    sim$half.logdet
  # f(rho|Z) = f(Z|rho)f(rho)/f(Z)
  # f(Z|rho) = f(Z|X, rho)f(X|rho)/f(X|Z, rho) for any X
  
  # f(rho|Z) = f(Z|rho)f(rho) f(X|Z) / ( f(Z|X) f(X) )
  
  # Try a new rho
  state2 <- state; state2$rho <- rnorm(1,state$rho, sd=state.rho$sigma)
  if(state2$rho <= 1 & state2$rho >= -1){
    prec2 <- precision_setup(prior, state2, state2$Q, state2$beta1.basis, iter.df.by.years)
    thompson <- thompson_forward(prec2$Omega_tt, lapply(prec2$covec, as.matrix), as.matrix(prec2$Omega_tt1))
    sim2 <- state_sim(thompson, Q = state2$Q) 
    # Calculate log(f(Z | rho))
    iter.df$BS <- X.to.df(basis.by.years, sim2$S, rows.by.years)
    S.mat <- as.matrix(do.call(cBind, sim2$S))
    ll_Z_rho_new <- ll_Z_X(iter.df, 'BS') + ll_X_rho.theta(S.mat, state2$rho, state2$Q) -
      .5* (t(S.mat[,1]) %*% prec2$P1inv %*% S.mat[,1]) - 
      sim2$half.logdet
  }else ll_Z_rho_new <- -Inf
#  print(ll_Z_rho)
#  print(ll_Z_rho_new)
  accept <- as.numeric(exp( ll_Z_rho_new - ll_Z_rho ))
#   print(accept)
#   print(runif(1) < accept)
  if( runif(1) < accept ){ # accept
    state <- state2
    # implied; sim <- sim
    state.rho$accept = state.rho$accept+1
  } else{ # reject
    # implied; state <- state
    sim <- sim2
  }
  if(is.na(state$rho)) browser()
  mc$rho[mciter+1] <- state$rho
  if( (mciter %% 50) == 0) {# update adaptive mcmc object
    state.rho$accept=0
    state.rho$sigma <- sqrt(2.38^2*(var(mc$rho[c(10:mciter),])))+.001
  }
  iter.df$BX <- X.to.df(basis.by.years, sim$X, rows.by.years)
  X.mat <- as.matrix(do.call(cBind, sim$X))
  mc.X[mciter+1, ,] <- X.mat
  
  # Update delta and Y = BX + delta
  # arrived at by -(x'Ax - 2b'x) ~ N(A^-1 b, A^-1)
  # Estimate V
  V <- iter.df$prox * 0
  V[tree.obs] <- 1/(1/state$sigma_sq_delta + iter.df$beta.1[tree.obs]^2/iter.df$sigma_sq_epsilon[tree.obs])
  resid <- iter.df$prox - iter.df$beta.0 - iter.df$beta.1*iter.df$BX
  covector <- resid * 0
  covector[tree.obs] <- (iter.df$beta.1[tree.obs]/iter.df$sigma_sq_epsilon[tree.obs])*resid[tree.obs]
  mn <- resid
  mn[tree.obs] <- V[tree.obs] * covector[tree.obs]
  iter.df$delta <- rnorm(nrow(iter.df), mean=mn, sd=sqrt(V))

  #####################################################
  # Update sigma_sq_delta 
  #  sigma_sq_delta <- MCMCpack::rinvgamma(1, .5+length(delta)/2, .5*sum(delta^2)/2)
  sigma_sq_delta <- MCMCpack::rinvgamma(1, 
                                        .5 + length(iter.df$delta)/2,
                                        .5 + sum((iter.df$delta)^2)/2)
  state$sigma_sq_delta <- sigma_sq_delta
  mc$sigma_delta[mciter+1] <- sqrt(state$sigma_sq_delta)
  
    # Update alpha
  # Refresh iter.df.by.species
  for(spec in 1:length(species_levels)){ # For each species
    yy <- iter.df$prox[row.by.species[[spec]]] # LHS data
    xx <- iter.df$BX[row.by.species[[spec]]] # Temperature data 
    nn <- iter.df$n[row.by.species[[spec]]] # variance parameter
    sigsig <- state$sigma_sq_epsilon[spec]/nn
    # Regress yy on xx with variance sigsig
    if (spec>1){
      XXZ <- cBind(fixed.design[[spec]], fixed.design[[spec]]*xx)
      S <- bdiag(diag(0,3),
                 spl.lat[[spec]]$ZSZ/(state$sigma.lat.0[spec]^2), 
                 spl.year[[spec]]$ZSZ/(state$sigma.year.0[spec]^2),
                 diag(0,3),
                 spl.lat[[spec]]$ZSZ/(state$sigma.lat.1[spec]^2),
                 spl.year[[spec]]$ZSZ/(state$sigma.year.1[spec]^2))
      alpha.sim <- ridgeRegression(as.matrix(XXZ/sqrt(sigsig)), as.matrix(S), yy/sqrt(sigsig))
      
      ###################################################################
      # Update sigma_sq_epsilon  
      yhat <- XXZ %*% as.vector(alpha.sim)
      SSE <- sum((yy-yhat)^2*nn)
      nu <- prior$nu.epsilon + SSE/2
      lam <- prior$lambda.epsilon + sum(nn)/2
      state$sigma_sq_epsilon[spec] <-  MCMCpack::rinvgamma(1, lam, nu)
      mc$sigma_epsilon[mciter+1, spec] <- sqrt(state$sigma_sq_epsilon[spec])
      
      ###################################################################
      # Update sigma_sq_alpha
      mc$alpha.0[mciter+1, spec, 1:3] <- alpha.sim[1:3]
      
      idx <- 4:13
      mc$alpha.lat.0[mciter+1, spec, 1:10] <- alpha.sim[idx]
      nu <- prior$nu_lat + sum(alpha.sim[idx]^2)
      lambda <- prior$lambda_lat + 10
      mc$sigma.lat.0[mciter+1, spec] <- sqrt(MCMCpack::rinvgamma(1, lambda, nu))
      
      idx <- 14:23
      mc$alpha.year.0[mciter+1, spec, 1:10] <- alpha.sim[idx]
      nu <- prior$nu_year + sum(alpha.sim[idx]^2)
      lambda <- prior$lambda_year + 10
      mc$sigma.year.0[mciter+1, spec] <- sqrt(MCMCpack::rinvgamma(1, lambda, nu))
      
      mc$alpha.1[mciter+1, spec, 1:3] <- alpha.sim[24:26]
      
      idx <- 27:36
      mc$alpha.lat.1[mciter+1, spec, 1:10] <- alpha.sim[idx]
      nu <- prior$nu_lat + sum(alpha.sim[idx]^2)
      lambda <- prior$lambda_lat + 10
      mc$sigma.lat.1[mciter+1, spec] <- sqrt(MCMCpack::rinvgamma(1, lambda, nu))
      
      idx <- 37:46
      mc$alpha.year.1[mciter+1, spec, 1:10] <- alpha.sim[idx]
      nu <- prior$nu_year + sum(alpha.sim[idx]^2)
      lambda <- prior$lambda_year + 10
      mc$sigma.year.1[mciter+1, spec] <- sqrt(MCMCpack::rinvgamma(1, lambda, nu))
      
    }else{#no coefficients on instrument
      mc$alpha.0[mciter+1, spec,1:3] <- c(0,0,0)
      mc$alpha.1[mciter+1, spec,1:3] <- c(1,0,0)
      mc$sigma_epsilon[mciter+1,1] <- 0
      state$sigma_sq_epsilon[1] <- 0
    }
  } # end for spec
  
  # Simulate theta
  state$Q <- inla.spde2.precision(spde1, theta=state$theta)
  state2 <- state
  if(mciter<50){
    R <- chol(state.theta$Sigma)
  }else{
    R <- chol(cov(mc$theta[c(2:(mciter)),]) + diag(.10 * apply(mc$theta[c(2:mciter),], 2, sd)))
  }
  state2$theta <- as.vector(state2$theta + t(R) %*% rnorm(2,0,1))
  state2$Q <- inla.spde2.precision(spde1, theta=state2$theta)
  
  ll_old <- ll_X_rho.theta(X.mat, state$rho, state$Q) + 
    dmvnorm(state$theta, prior$theta.mu, diag(prior$theta.sigma), log = TRUE)
  ll_new <- ll_X_rho.theta(X.mat, state2$rho, state2$Q) + 
    dmvnorm(state2$theta, prior$theta.mu, diag(prior$theta.sigma), log = TRUE)
  accept <- exp(as.numeric(ll_new - ll_old))
  
  if( runif(1) < accept ){ # accept
    state <- state2
    # implied; sim <- sim
    state.theta$accept = state.theta$accept+1
  } else{ # reject
    # implied; state <- state
  }
  mc$theta[mciter+1,] <- state$theta
  if( (mciter %% 50) == 0) {# update adaptive mcmc object
    state.theta$accept=0
    state.theta$Sigma <- 2.38^2/2*(cov(mc$theta[c(10:mciter),]) + diag(.01 * apply(mc$theta[c(10:mciter),], 2, sd)))
  }

  # Update the iter.df object
  for( s in 2:length(species_levels) ){
    alpha.0 <-c(mc$alpha.0[mciter+1, s, ], mc$alpha.lat.0[mciter+1,s, ],  mc$alpha.year.0[mciter+1,s ,])
    beta.0 <- fixed.design[[s]] %*% alpha.0 #create site.specific intercept
    iter.df$beta.0[row.by.species[[s]]] <- as.vector(beta.0)
    #NOTE: I just assumed that B had the same row ordering as row.by.species
    alpha.1 <-c(mc$alpha.1[mciter+1, s, ], mc$alpha.lat.1[mciter+1,s, ],  mc$alpha.year.1[mciter+1,s ,])
    beta.1 <- fixed.design[[s]] %*% alpha.1 #create site.specific slopes
    iter.df$beta.1[row.by.species[[s]]] <- as.vector(beta.1)
  }
  rm(s, alpha.0, beta.0, alpha.1, beta.1)
  iter.df$sigma_sq_epsilon <- state$sigma_sq_epsilon[unclass(iter.df$species)]
  iter.df$sigma_sq_nu      <- iter.df$beta.1^2 * state$sigma_sq_delta + iter.df$sigma_sq_epsilon
  iter.df.by.years <- split(iter.df, factor(iter.df$year, years))
  state$beta1.basis <- mapply(function(x,y) return( x * y$beta.1 ), basis.by.years, iter.df.by.years)
  
  state$sigma_sq_epsilon     <- mc$sigma_epsilon[mciter+1,]^2
  state$sigma_sq_delta       <- mc$sigma_delta[mciter+1]^2
  state$sigma.0              <- mc$sigma.0[mciter+1,]
  state$sigma.1              <- mc$sigma.1[mciter+1,]
  state$sigma.lat.0          <- mc$sigma.lat.0[mciter+1,]
  state$sigma.lat.1          <- mc$sigma.lat.1[mciter+1,]
  state$sigma.year.0         <- mc$sigma.year.0[mciter+1,]
  state$sigma.year.1         <- mc$sigma.year.1[mciter+1,]
  
  # Evaluate likelihood
  resid <- iter.df$prox - iter.df$beta.0 - iter.df$beta.1 * (iter.df$BX + iter.df$delta)
  lp_epsilon <- - .5 * sum(log(iter.df$sigma_sq_epsilon[tree.obs]/iter.df$n[tree.obs])) - 
    .5 * sum(resid[tree.obs]^2/(iter.df$sigma_sq_epsilon[tree.obs]/iter.df$n[tree.obs]))
  lp_delta <- -.5*nrow(iter.df)*log(state$sigma_sq_delta) - .5*sum(iter.df$delta^2)/state$sigma_sq_delta
  lp_X <- as.numeric(ll_X_rho.theta(X.mat, state$rho, state$Q) - .5* (t(X.mat[,1]) %*% prec$P1inv %*% X.mat[,1]))
  lp_alpha_fun <- function(spec){
    K <- bdiag(diag(0,3),
                 spl.lat[[spec]]$ZSZ/(state$sigma.lat.0[spec]^2), 
                 spl.year[[spec]]$ZSZ/(state$sigma.year.0[spec]^2),
                 diag(0,3),
                 spl.lat[[spec]]$ZSZ/(state$sigma.lat.1[spec]^2),
                 spl.year[[spec]]$ZSZ/(state$sigma.year.1[spec]^2))
    eigK <- eigen(K)$values
    eigK <- eigK[eigK>1e-6]
    alpha <- c(mc$alpha.0[mciter+1,spec,], mc$alpha.lat.0[mciter+1,spec,], mc$alpha.year.0[mciter+1,spec,],
               mc$alpha.1[mciter+1,spec,], mc$alpha.lat.1[mciter+1,spec,], mc$alpha.year.1[mciter+1,spec,])
    return(as.numeric(sum(log(eigK))/2 - 0.5 * t(alpha) %*% (K %*% alpha)))
  }
  lp_alpha <- sapply(2:19, lp_alpha_fun)
  lp_theta <- dmvnorm(state$theta, prior$theta.mu, diag(prior$theta.sigma), log = TRUE)
  lp_sigma_epsilon <- log(MCMCpack::dinvgamma(state$sigma_sq_epsilon[-1], prior$lambda.epsilon, prior$nu.epsilon))
  lp_sigma_delta <- log(MCMCpack::dinvgamma(state$sigma_sq_delta, prior$lambda.delta, prior$nu.delta))
  lp_sigma_lat.0 <- log(MCMCpack::dinvgamma(state$sigma.lat.0[-1], prior$lambda_lat, prior$nu_lat))
  lp_sigma_lat.1 <- log(MCMCpack::dinvgamma(state$sigma.lat.1[-1], prior$lambda_lat, prior$nu_lat))
  lp_sigma_year.0 <- log(MCMCpack::dinvgamma(state$sigma.year.0[-1], prior$lambda_year, prior$nu_year))
  lp_sigma_year.1 <- log(MCMCpack::dinvgamma(state$sigma.year.1[-1], prior$lambda_year, prior$nu_year))
  lp_post <- lp_epsilon + lp_delta + lp_X + sum(lp_alpha) + lp_theta + sum(lp_sigma_epsilon) + 
    lp_sigma_delta + sum(lp_sigma_lat.0) + sum(lp_sigma_lat.1) + sum(lp_sigma_year.0) + sum(lp_sigma_year.1)
  mc$log_p_vec[mciter+1, ] <- c(lp_epsilon, lp_delta, lp_X, sum(lp_alpha), lp_theta, sum(lp_sigma_epsilon),
                                lp_sigma_delta, sum(lp_sigma_lat.0), sum(lp_sigma_lat.1), sum(lp_sigma_year.0),
                                sum(lp_sigma_year.1))
  mc$log_p[mciter+1] <- lp_post
  print(c( mc$rho[mciter+1], mc$theta[mciter+1,]))
  print(mciter)
}

#save(list=ls(), file='mcout.Rdata')
rm(NMC)
ffsave(list=ls(), file='mcout.ff', rootpath='/Users/nnagle/Dropbox/git_root/climate-bayes/R')
```

```{r eval=FALSE}
#quick plot of field
plot.data <- data.frame(cbind(inla.mesh.map(loc=mesh2$loc, projection="longlat", inverse=FALSE),
                              X.mat[,22]))
names(plot.data) <- c('lon','lat', 'temp')
ggplot(data=plot.data) + geom_point(aes(x=lon, y=lat, color=temp)) + 
  coord_map(projection = 'mollweide', orientation=c(110,-100,0)) +
  scale_color_gradient2(low=muted("blue"), high=muted("red"))

# plot of lag-1 ac

plot.data <- data.frame(cbind(inla.mesh.map(loc=mesh2$loc, projection="longlat", inverse=FALSE),
                              apply(X.mat, 1, function(x) acf(x)$acf[2])))
names(plot.data) <- c('lon','lat', 'ac')
ggplot(data=plot.data) + geom_point(aes(x=lon, y=lat, color=temp)) + 
  coord_map(projection = 'mollweide', orientation=c(110,-100,0)) +
  scale_color_gradient()

```

```{r, eval=FALSE}
# Create giant sparse banded matrix.  Use kronecker to get off diagonals...
bdiag(prec$Omega_tt) ->temp1
temp2 <- kronecker(bandSparse(n=N, k=c(-1,1)),Q)
Omega <- temp1 - state2$rho*temp2
OmegaC <- Cholesky(Omega) # That takes a bit of time... 12 seconds?
cc <- do.call(c, lapply(prec$covec, as.vector))

mu <- solve(OmegaC, cc) # Nearly instantaneous
mu <- matrix(mu, Size, N)
# I have mu here with S above... same result!
# The determinant matches up too!
# and the method above is ten times quicker.
# t(as.vector(X.mat)-as.vector(S.mat)) %*% solve(OmegaC, as.vector(X.mat)-as.vector(S.mat))
# but that doesn't match up???
t(as.vector(X.mat)-as.vector(S.mat)) %*% Omega %*% (as.vector(X.mat)-as.vector(S.mat))
```
