---
title: "sample Instrument and Proxy"
author: "Nicholas Nagle"
date: "February 13, 2015"
output: pdf_document
---
## Data Model

We define the list of measured data to be $\{Y_{tk}i\}$, where $t$ indexes the time period and $k$ indexes the measurement type .  There is one measurement type for each tree species ($k=1,\ldots,n_{\mbox{species}}$) and one for the set of instrumental measurements.  
The unknown temperature field at each location is indicated by the variable $Z_t$.
The Instrument and Proxy data follow the linear model
$$\mathbf{Y}_{t,k} = \mathbf{X}_{t,k}\boldsymbol{\beta}_{0,k} + \mathbf{Z}_{t,k}\boldsymbol{\beta}_{1,k} + \boldsymbol{\zeta}_{t,k}$$
where the error follows a normal law $\boldsymbol{\zeta}_t \sim N(\mathbf{0}, \boldsymbol{\Sigma}_{\zeta, t,k})$. We simplify the notation by stacking the data and writing: $\mathbf{Y}_t = \mathbf{X}_t\boldsymbol{\beta}_0 + \mathbf{Z}_t\boldsymbol{\beta}_1 + \boldsymbol{\zeta}_t$. 
For the time, we simplify the variance matrix to be $\sigma^2_{k}\boldsymbol{I}$.  
Additionally, we will assume that there is no measurement error in the instrument record (i.e. $(\beta_{0,k},\ \beta_{1,k},\ \sigma^2_{k})=(0, 1, 0)$ for $k=$'instrument').  
Measurement error in the instrument record is subsumed under the variance of the temperature field $Z_t$.


I assume that the errors $\zeta$ have no temporal or spatial autocorrelation. 
Temporal autocorrelation may be important for the tree species.

```{r load data}
rm(list=ls())
library(dplyr)
library(tidyr)
library(Matrix)
library(INLA)
library("mvtnorm")
library(abind)

# Load the sat data:
load('~/Dropbox/git_root/climate-bayes/data/indiv.station.Rdata')
# Load the tree ring data:
load('~/Dropbox/git_root/climate-bayes/data/itrdb_meta.Rdata')
# Load the spatial matrices that were created by 25_create_spatial_field.R
load('~/Dropbox/git_root/climate-bayes/data/spatial_fields.Rdata')

# Convert species_code to a facter
tree.meta <- tree.meta %>% mutate(species = as.factor(species_code))

# Count the number of distinct species:
num.species <- nlevels(tree.meta$species)



# alpha_t is a 580 x 1 vector
# y_t is a 914 tree plus 106 sas locs = 1020 x 1 vector

# beta has
# 18 intercepts for each species
# 18 slopes for each species
# 1 mean for alpha

# Z_grid = 106 x 580 matrix
# Z_tree is a 914 x 580 matrix: diag(beta) %*% A_tree


# Find number of years
years <- seq(1850, 2010)
  
N <- length(years)

```


Create a flat dataframe for all measurement vars, with the columns:
year, site, species, measure, count
```{r, eval=TRUE}
# Process tree ring data here...
# Create a flat data frame out of crn
# For each chronology, create a dataframe with cols:
#  ID, species, year, rwi, n
crn.df <- vector(mode='list', length=length(crn))
for(i in 1:length(crn.df)){
  crn.df[[i]] <- as_data_frame(crn[[i]])
  names(crn.df[[i]]) <- c('rwi', 'n')
  crn.df[[i]] <- data_frame(ID=as.character(i), species=tree.meta$species_code[i], 
                            year=as.numeric(row.names(crn[[i]])),
                            prox = crn.df[[i]]$rwi, n=crn.df[[i]]$n)
}

# Merge the instrument and proxy records:
# We aren't using the tree data yet
ann.temp <- ann.temp %>% ungroup %>% transmute(ID=station, species='INST', year=year2, prox=sat, n=1)
measure <- bind_rows(ann.temp, bind_rows(crn.df)) %>% ungroup

# Create the design matrix, rearranging so INST is first
species_levels <- measure %>% filter(species != 'INST') %>% distinct(species) %>%
  arrange(species) %>% .[['species']]
species_levels <- c('INST', species_levels)

measure <- measure %>% mutate(species = factor(species, levels=species_levels))
design <-  sparse.model.matrix(~species-1, data=measure)
row.names(design) <- measure$ID
```


---

## Process Model

The hidden temerature field $Z$ follows a vector autoregressive process:
$$\mathbf{Z}_t = \mathbf{B}_t\boldsymbol{\alpha}_t + \delta_t$$
where $\delta_t\sim N(0, \sigma^2_\delta\mathbf{I})$ and 
$$\boldsymbol{\alpha}_t = \rho \boldsymbol{\alpha}_{t-1}+\boldsymbol{\epsilon}_t$$ 
with $\boldsymbol{\epsilon}\sim N(0, \mathbf{Q}^{-1})$.  
The temperature field is specified as a Markov Random Field so that the precision matrix $\mathbf{Q}(\theta)$ is sparse.


Prepare the basis matrices.
The basis matrix can be indexed by the measurestation variable

```{r, eval=TRUE}
basis <- rBind(A.inst, A.tree)
# Create a data.frame with site characteristics
site <- data_frame(ID=row.names(basis)) %>% 
  left_join(., 
            measure %>% distinct(ID) %>% select(ID, species))
```

```{r, eval=TRUE}
# Parameters for the spde:
sigma0 <- 1 # standard deviation
range0 <- .8 # range
# convert into tau and kappa
kappa0 = sqrt(8)/range0
tau0 = 1/(sqrt(4*pi)*kappa0*sigma0)

spde1 <- inla.spde2.matern(mesh=mesh2,
                           B.tau=cbind(log(tau0),1,0),
                           B.kappa=cbind(log(kappa0), 0, 1),
                           theta.prior.mean=c(0,0),
                           theta.prior.prec=c(1,1))
```


## Prior Distributions

The parameters of the model are $(\beta_{0,k}, \beta_{1,k},\sigma_{k}, \sigma_{\delta}, \boldsymbol{\alpha}_0)$.  The model is completed by specifying conjugate priors on these of 
$$\beta_{0,k}\sim N(0, \sigma^2_0)$$
$$\beta_{1,k}\sim N(0, \sigma^2_1)$$
$$\sigma^2_{l}\sim IG(\zeta_l, \zeta_l)$$
$$\boldsymbol{\alpha}_0 \sim N(0, \sigma_\alpha^2\mathbf{I})$$
$\theta$ does not have a conjugate prior, and we simply specify it here as $\pi$.  
We specify a non-conjugate $U(0,1)$ prior on $\rho$.


Evaluate a good prior for theta.  I want to make sure that theta translates into good values for sigma and range:

```{r eval=TRUE}
data.frame(theta1=rnorm(1000,0, sd=1/1), theta2=rnorm(1000, 0, 1/1)) %>% 
  mutate(logtau=(log(tau0)+theta1), logkappa=(log(kappa0)+theta2)) %>%
  mutate(range= sqrt(8)/exp(logkappa), sigma=1/(sqrt(4*pi)*exp(logtau+logkappa))) %>%
  dplyr::select(range, sigma) %>% summary
```
That seems good.

```{r, eval=TRUE}
# Set precision:
Q <- inla.spde2.precision(spde1, theta=c(0,0))
```

```{r alpha 1 prior, eval=TRUE}
mu_1 <- 0
sigma_sq_1 <- 4
```

```{r mu prior, eval=TRUE}
mu_0 = 0
sigma_sq_mu = 1e-12
```

```{r beta prior, eval=TRUE}
beta_0 = rep(1,18)
sigma_sq_beta_0 = 3

beta_1 = rep(0,18)
sigma_sq_beta_1 = 3

```

```{r prior on siga sq Instrument, eval=TRUE}
nu_I <- .5
lambda_I <- .5
```

```{r prior on sigma sq proxy, eval=TRUE}
nu_P <- .5
lambda_P <- .5
```

```{r initialize MC object, eval=TRUE}
# y has a 106 x 1 vector
# alpha has a 580 x 1 vector
# beta is the mean mu of alpha.
# there is no X.
# W = (1-rho) * mu
# T = rho*I

Size <- mesh2$n


# Markov Chain Setup
NMC <- 1
# Save the storage objects
mc <- list(theta = matrix(NA, NMC, 2),
           alpha = array(NA, dim=c(NMC, Size, N)),
           mu = matrix(NA, NMC, 1),
           beta_0 = matrix(NA, NMC, 19), # the first should always be 0, it is the instrument
           beta_1 = matrix(NA, NMC, 19), # the first should always be 1, it is the instrument
           rho = matrix(NA, NMC,1),
           sigma_delta = matrix(NA, NMC,1),
           sigma_y = matrix(NA, NMC, 19)) #order matters
mc$theta[1,] <- c(0,0)
mc$alpha[1,,] <- rep(0, Size*N)
mc$mu[1] <- 0
mc$beta_0[1,] <- c(0, rep(1,18))
mc$beta_1[1,] <- c(1, rep(0,18))
mc$rho[1] <- .8

# Use variance of proxies for the initial sigma_y values.
mc$sigma_delta[1] <- measure %>% ungroup %>% filter(species=='INST') %>% .[['prox']] %>% sd
mc$sigma_y[1,] <- 
  c(0, # assume no extra error for measurements
    rep(measure %>% ungroup %>% filter(species!='INST') %>% .[['prox']] %>% sd, 18))
mc$sigma_y[1,] <- mc$sigma_y[1,] * (10^2)
```

```{r woodbury function, eval=TRUE}
woodbury_solve <-  function(A, b){
  # Solve the equation Ax=b, 
  #   where A = UCV+D
  # The solve is A^ = D^ + D^ U (C^ + V D^ U)^ V D^
  #  where X^ = X^{-1}
  #
  # Inputs:
  # A$D (possible a Cholesky factorization thereof)
  # A$U
  # A$V (defaults to t(A$U) )
  # A$Cinv
  #
  A$V <- t(A$U)
  Db <- solve(A$D, b)
  VDU <- A$V %*% solve(A$D, A$U)
  CiVDU <- A$Cinv + VDU 
  return(Db - solve(A$D, A$U) %*% solve(CiVDU, A$V %*% Db))
}


```


```{r grow MC object, eval=TRUE}
#######################################################################
# Markov Chain Loop
NMC= 1
start <- nrow(mc$theta)
# grow the mc save object
mc$theta <- rBind(mc$theta, matrix(NA, NMC, 2))
mc$alpha <- abind(mc$alpha, array(NA, dim=c(NMC, Size, N)), along=1)
mc$mu <- rBind(mc$mu, matrix(NA, NMC,1))
mc$beta_0 <- rBind(mc$beta_0, matrix(NA, NMC, 19))
mc$beta_1 <- rBind(mc$beta_1, matrix(NA, NMC, 19))
mc$rho <- rBind(mc$rho, matrix(NA, NMC, 1))
mc$delta <- rBind(mc$delta, matrix(NA, NMC, 1))
mc$sigma_y <- rBind(mc$sigma_y, matrix(NA, NMC, 19))

K0 <- .sparseDiagonal(n=Size, x=sigma_sq_1)

measure <- measure %>% filter(year %in% years)
basis <- basis[row.names(basis) %in% unique(measure$ID), ]
design <- sparse.model.matrix(~species-1, data=measure)
site <- site[site$ID %in% unique(measure$ID), ]
site$species <- factor(site$species, levels=levels(measure$species))



sites.by.years <- split(measure$ID, measure$year)
rows.by.years <- split(1:nrow(measure), measure$year)
measure.by.years <- split(measure, measure$year)
design.by.years <- lapply(rows.by.years, function(x) design[x,  ])
basis.by.years <- lapply(sites.by.years, function(x) basis[x, ])
Observation <- split(left_join(measure, site %>% mutate(row=1:nrow(site)) %>% .[['row']], measure$year)
Observation <- lapply(Observation, function(x) sparseMatrix(i=1:length(x), j=x))

rows.by.species <- split(1:nrow(measure), measure$species)
```

## Posterior Distributions
$Z_{t,k}$ is a $N_{k_t}\times S$ matrix.  $Z_t$ is a $N_t \times S$ matrix.  So there must be a $N_t \times N_{k_t}$ selection matrix $H_t$.  We can write the joint distribution as:

$$\frac{n-1}{2}\log|Q(\boldsymbol{\Theta})|-
\frac{1}{2}\sum_{t=1}^{n-1}(\boldsymbol{\alpha}_{t+1}- \rho\boldsymbol{\alpha}_{t})^T 
\mathbf{Q}(\boldsymbol{\Theta})(\boldsymbol{\alpha}_{t+1}- \rho\boldsymbol{\alpha}_{t}) + $$

$$-\frac{1}{2}\sum_{t=1}^n \log | \boldsymbol{\Sigma}_{\zeta,t}| - 
\frac{1}{2}\sum_{t=1}^n (\mathbf{Y}_{t} - \mathbf{X}_{t}\boldsymbol{\beta}_{0} - \mathbf{Z}_{t}\boldsymbol{\beta}_{1})^T \Sigma_{\zeta, t}^{-1}(\mathbf{Y}_{t} - \mathbf{X}_{t}\boldsymbol{\beta}_{0} - \mathbf{Z}_{t}\boldsymbol{\beta}_{1})$$

$$-\frac{1}{2}\log|\sigma^2_\delta\mathbf{I}| - \sigma_\delta^{-2}\frac{1}{2}(\mathbf{Z}_t-\mathbf{B}_t\boldsymbol{\alpha}_t)^T(\mathbf{Z}_t-\mathbf{B}_t\boldsymbol{\alpha}_t)$$

$$-\frac{1}{2}\log|\boldsymbol{\Sigma}_0| - \frac{1}{2}(\boldsymbol{\alpha}_1-\boldsymbol{\mu}_0)^T\boldsymbol{\Sigma}_0^{-1}(\boldsymbol{\alpha}_1-\boldsymbol{\mu}_0)$$

$$-\frac{1}{2}\log \sigma^2_\mu - \frac{1}{2}\frac{(\mu-\mu_0)^2}{\sigma^2_\mu}$$

$$-\frac{1}{2}\log|\sigma_\beta^{2}I_2| - \sigma_\beta^{-2} (\beta)^T(\beta)$$

### Isolate $\beta$


$$\log f(\beta\ |\ \cdot) \doteq  -\frac{1}{2 \sigma^2_\zeta}(\mathbf{Y}_t-\mathbf{C}_t\boldsymbol{\beta})^T(\mathbf{Y}_t-\mathbf{C}_t\boldsymbol{\beta})^T\} - \frac{1}{2\sigma^2_\beta} \boldsymbol{\beta}^T\boldsymbol{\beta}$$

$$\doteq -\frac{1}{2 \sigma^2_\zeta}\left(\boldsymbol{\beta}^T(\mathbf{C}^T\mathbf{C}+\frac{\sigma^2_\zeta}{\sigma^2_\beta}\mathbf{I})\boldsymbol{\beta} - 2 \mathbf{C}^T\mathbf{Y}\boldsymbol{\beta}\right)$$

$$\boldsymbol{\beta}\sim N\left((\mathbf{C}^T\mathbf{C}+\frac{\sigma^2_\zeta}{\sigma^2_\beta}\mathbf{I})^{-1}\mathbf{C}^T\mathbf{Y}, (\mathbf{C}^T\mathbf{C}+\frac{\sigma^2_\zeta}{\sigma^2_\beta}\mathbf{I})^{-1}\right)$$

### Isolate $Z_{t,k}$
$$\log f(Z_{t,k}\ |\ \cdot) \doteq -\frac{1}{2\sigma^2_\zeta}\left( (Y_{t,k} - X_{t,k}{\beta}_0 - {Z}_{t,k}{\beta}_1)^T (Y_{t,k} - {X}_{t,k}{\beta}_0 - {Z}_{t,k}{\beta}_1) \right) -\frac{1}{2\sigma^2_\delta}\left( {Z}_{t,k} - {B}_{t,k}{\alpha}_{t,k} \right)^T\left( {Z}_{t,k} - {B}_{t,k}{\alpha}_{t,k} \right)$$

$$\doteq -\frac{1}{2}\left( \left( \frac{1}{\sigma^2_\delta}+ \beta_1^2\frac{1}{\sigma^2_\zeta}\right) Z_{t,k}^2 - 2 ( \frac{1}{\sigma^2_\zeta}\beta_{1,k}(Y_{t,k}-X_{t,k}\beta_{0,k}) +\frac{1}{\sigma^2_\delta} \mathbf{B}_{t,k}\boldsymbol{\alpha}) Z_{t,k} \right)$$

$$Z_{t,k}\sim N\left(\left( \frac{1}{\sigma^2_\delta}+ \beta_1^2\frac{1}{\sigma^2_\zeta}\right)^{-1}\left(\frac{1}{\sigma^2_\zeta}\beta_{1,k}(Y_{t,k}-X_{t,k}\beta_{0,k}) +\frac{1}{\sigma^2_\delta} \mathbf{B}_{t,k}\boldsymbol{\alpha}\right),\left( \frac{1}{\sigma^2_\delta}+ \beta_1^2\frac{1}{\sigma^2_\zeta}\right)^{-1}\right)$$


### Isolate $\sigma^2_\delta$

$$\left(\frac{1}{\sigma^2_\delta}\right)^{\lambda_\delta+1} \exp\left(\frac{\nu_\delta}{\sigma^2_\delta}\right) \prod_t\prod_s \left(\frac{1}{\sigma^2_\delta}\right)^{1/2}\exp\left(\frac{(Z_{t,s}-\mathbf{B}_{t,s}\boldsymbol{\alpha}_t)^2}{2\sigma^2_\delta}\right)$$

$$\propto \left(\frac{1}{\sigma^2_\delta}\right)^{\lambda_\delta+1} \left(\frac{1}{\sigma^2_\delta}\right)^{\frac{1}{2}S} \exp\left(\frac{\nu_\delta}{\sigma^2_\delta}\right) \exp\left\{\sum_t\sum_s\frac{(Z_{t,s}-\mathbf{B}_{t,s}\boldsymbol{\alpha}_t)^2}{2\sigma^2_\delta}\right\}$$

$$(\sigma^2_\delta)^{-\lambda_\delta-1-\frac{1}{2}S}\exp\left\{ \sigma^{-2}_\delta\left( - \nu_\delta - \sum_t\sum_s\left\{ \frac{(Z_{t,s}-\mathbf{B}_{t,s}\boldsymbol{\alpha}_t)^2}{2}\right) 
\right\} \right\}$$

Which is $IG(\lambda_\delta+\frac{1}{2}S, \nu_\delta + \sum_s\sum_t\left(\frac{(Z_{t,s}-\mathbf{B}_{t,s}\boldsymbol{\alpha}_t)^2}{2}\right))$


### Isolate $\sigma^2_{\zeta,k}$
{
$$\left(\frac{1}{\sigma^2_{\zeta,k}}\right)^{\lambda_{\zeta,k}+1} \exp\left(\frac{\nu_{\zeta,k}}{\sigma^2_{\zeta,k}}\right) \prod_t\prod_{s_k} \left(\frac{1}{\sigma^2_{\zeta,k}}\right)^{1/2}\exp\left(\frac{(Y_{t,s}- X_{t,s}\beta_{0,k} - Z_{t,s}\beta_{1,k})^2}{2\sigma^2_{\zeta,k}}\right)$$

$$\propto \left(\frac{1}{\sigma^2_{\zeta,k}}\right)^{\lambda_{\zeta,k}+1} \left(\frac{1}{\sigma^2_{\zeta,k}}\right)^{\frac{1}{2}S_k} \exp\left(\frac{\nu_{\zeta,k}}{\sigma^2_{\zeta,k}}\right) \exp\left\{\sum_t\sum_{s_k}\frac{(Y_{t,s}- X_{t,s}\beta_{0,k} - Z_{t,s}\beta_{1,k})^2}{2\sigma^2_{\zeta,k}}\right\}$$
which is $IG(\lambda_{\zeta,k}+\frac{1}{2}S_k, \nu_{\zeta,k}+\sum_{s_k}\sum_t\left(\frac{(Y_{t,s}-X_{t,s}\beta_{0,k}-Z_{t,s}\beta_{1,k})^2}{2}\right))$
}

```{r eval=TRUE}
for(mciter in (start):(start+NMC-1)){
  mu      <- mc$mu[mciter]
  rho     <- mc$rho[mciter]
  beta_0  <- mc$beta_0[mciter,]
  beta_1  <- mc$beta_1[mciter,]
  sigma_sq_y     <- mc$sigma_y[mciter,]^2
  sigma_sq_delta <- mc$sigma_delta[mciter]^2
  
  # Z_1 is beta1.basis
  beta1.basis <- mapply(function(x,y) return(x * beta_1[y$species]), basis.by.years, measure.by.years)

  ####################################################################
  # Using the technique in Mcausland
  # Calculate prior variance on alpha1
  P1 <- .sparseDiagonal(n=Size, x=sigma_sq_1)
  P1inv <- .sparseDiagonal(n=Size, x=1/sigma_sq_1)
  # Calculate T * A_22 *T (refer to McCausland) # The variance due to
  #   carrying forward the previous state
  TA22T <- rho^2 * Q
  
  # Calculate the idiosyncratic precision of each obs
  #  This is the beta^2 * (field nugget) plus measurement error
  A11 <- lapply(measure.by.years, function(x) 
    sigma_sq_y[unclass(x$species)]/x$n + sigma_sq_delta * beta_1[unclass(x$species)]^2)
  A11 <- lapply(A11, function(x) 1/x)
  A11 <- lapply(A11, function(x) {x[!is.finite(x)] <- 0; return(x)})
  A11 <- lapply(A11, function(x) .sparseDiagonal(n=length(x), x=x))

  Omega_tt <- vector(mode='list', length=N)
  Omega_tt[[1]] <- t(beta1.basis[[1]]) %*% A11[[1]] %*% beta1.basis[[1]] + TA22T + P1inv
  for(t in 2:N){
    Omega_tt[[t]] <- t(beta1.basis[[t]]) %*% A11[[t]] %*% beta1.basis[[t]] + TA22T + Q
  }
  Omega_tt[[N]] <- t(beta1.basis[[N]]) %*% A11[[N]] %*%  beta1.basis[[N]] + Q
  
  # Precompute Omega_t,t+t
  Omega_tt1 <- -rho * Q  #(it's the same for every time period)

  # Precompute c (McCausland eqn 15.)
  # Note: Z_11 is beta1.basis
  c <- vector(mode='list', length=N)
  resid <- as.vector(measure$prox - design %*% beta_0 )
  for(t in 1:N){ 
    c[[t]] <- t(beta1.basis[[t]]) %*% A11[[t]] %*% resid[rows.by.years[[t]]]
    }

  p0 <- proc.time()
  Chol_omega <- vector(mode='list', length=N)
  Chol_omega[[1]] <- Cholesky(Omega_tt[[1]], LDL=FALSE, perm=FALSE)
  # Note, that when following McCausland, that t(Omega_t-1,t) = Omega_tt1
  for(t in 2:N){
    temp <- Omega_tt[[t]] - 
      (Omega_tt1) %*% solve(Chol_omega[[t-1]], t(Omega_tt1), system='A')
    temp <- (temp +t(temp))/2
    # this is the same: but slower:
    # Omega_tt[[t]] - crossprod(solve(Chol_omega[[t-1]], t(Omega_tt1), system='L'))
    Chol_omega[[t]] <- Cholesky(((temp)), LDL=FALSE, perm=FALSE)
    #Chol_omega[[t]] <- chol(as.matrix(temp), permute=TRUE)
  }
  proc.time() - p0
  
  
  # LO = Lambda_t \ Omega_t1
  LO <- vector(mode='list', length=N)
  for(t in 1:N){LO[[t]] <- drop0((solve(Chol_omega[[t]], Omega_tt1, system='L')))}

  m <- vector(mode='list', length=N)
  m[[1]] <- solve(Chol_omega[[1]], c[[1]], system='A')
  for(t in 2:N){
    m[[t]] <- solve(Chol_omega[[t]], c[[t]] - Omega_tt1 %*% m[[t-1]], system='A')
  }
  rm(c)

  #############################################
  # And here it is... simulate alpha
  alpha <- vector(mode='list', length=N)
  epsilon <- rnorm(n=nrow(Q))
  alpha[[N]] <- m[[N]] + solve(Chol_omega[[N]], epsilon, system='Lt')
  for(t in seq(N-1, 1, -1)){
    epsilon <- rnorm(n=nrow(Q))
    alpha[[t]] <- m[[t]] + solve(Chol_omega[[t]], epsilon - LO[[t]] %*% alpha[[t+1]], system='Lt')
  }
  Balpha.hat <- mapply(function(b,a) b %*% a, basis.by.years,alpha)
  Balpha.hat <- do.call(c, lapply(Balpha.hat, as.vector))
  Balpha.hat <- data_frame(ID=as.vector(do.call(c, rows.by.years)), ba = Balpha.hat) %>%
    arrange(ID) %>% .[['ba']]  

  alpha <- as.matrix(do.call(cBind, alpha))
  
  mc$alpha[mciter+1, ,] <- alpha
  
  #############################################
  # And here it is... simulate delta
  # At all of the instrument sites... delta is just the residual
  # at the proxy sites, var(delta) = 1/(1/var(delta)+1/var(y))
  temp_data <- data_frame(ID=measure$ID, Y=measure$prox, species=measure$species,
                          XBO=beta_0[unclass(measure$species)],
                          Balpha=Balpha.hat,
                          sigma_sq_y=sigma_sq_y[unclass(measure$species)],
                          b1=beta_1[unclass(measure$species)])
  temp_data <- temp_data %>% mutate(resid=Y-XBO)
  temp_data <- temp_data %>% mutate(c_z=Balpha/sigma_sq_delta + 
                                    ifelse(sigma_sq_y>0, b1*resid/sigma_sq_y, 0)) %>%
  mutate(var_z=1/sigma_sq_delta + 
         ifelse(sigma_sq_y>0,b1^2/sigma_sq_y,0)) %>%
  mutate(var_z=1/var_z)
  # simulate Z
  Z <- rnorm(n=nrow(temp_data),mean=temp_data$c_z*temp_data$var_z, sd = sqrt(temp_data$var_z)) 

  #####################################################
  # Update sigma_sq_delta
  #  sigma_sq_delta <- MCMCpack::rinvgamma(1, .5+length(delta)/2, .5*sum(delta^2)/2)
  sigma_sq_delta <- MCMCpack::rinvgamma(1, 
                                        .5 + length(Z)/2,
                                        .5 + sum((Z-temp_data$Balpha)^2)/2)

  mc$sigma_delta[mciter+1] <- sqrt(sigma_sq_delta)

  ###################################################################
  # Update rho
  mu=0
  c_rho <- sum(diag( t(alpha[,-N]-mu) %*% Q %*% (alpha[,-1]-mu)))
  V_rho <- 1 / sum(apply(alpha[,-N]-mu, 2, function(x) as.numeric(t(x) %*% Q %*% x)))
  rho <- msm::rtnorm(1, mean=V_rho*c_rho, sd=sqrt(V_rho), lower=0, upper=1)
  mc$rho[mciter+1] <- rho
  
  ##############################################################################
  # Loop through each species, updating beta0, beta1, and sigma_sq
  for(spec in 1:length(species_levels)){
	  ###################################################################
	  # Update beta.  This is a ridge regression using each species.
	  yy <- temp_data %>% filter(species==species_levels[spec]) %>% .[['Y']]
	  xx <- Z[rows.by.species[[spec]]]
	  nn <- measure$n[rows.by.species[[spec]]]
	  sigsig <- sigma_sq_y[spec]/nn
	  XX <- cbind(rep(1, length(xx)), xx)
      if (spec>1){
          udv <- svd(XX/sqrt(sigsig))
          # normal reg udv$v %*% diag(1/udv$d) %*% t(udv$u) %*% (yy/sqrt(sigsig))
          lambda <- 1/c(sigma_sq_beta_0, sigma_sq_beta_1)
          beta_mn <- udv$v %*% (diag(1/(udv$d^2 + lambda))) %*% diag(udv$d) %*% t(udv$u) %*% (yy/sqrt(sigsig))
          beta_cov <- udv$v %*% (diag(1/(udv$d^2 + lambda))) %*% t(udv$v)
          beta_sim <- rmvnorm(1, beta_mn, beta_cov)

          ###################################################################
          # Update sigma_sq_y.  
          yhat <- XX %*% as.vector(beta_sim)
          SSE <- sum((yy-yhat)^2*nn)
          nu <- nu_I + SSE/2
          lam <- lambda_I + sum(nn)/2
          sigma_sq_y[spec] <-  MCMCpack::rinvgamma(1, lam, nu)

      }else {beta_sim <- c(0,1) } 
   
      beta_0[spec] <- beta_sim[1]
      beta_1[spec] <- beta_sim[2]
  }
  mc$beta_0[mciter+1,] <- beta_0
  mc$beta_1[mciter+1,] <- beta_1
  mc$sigma_y[mciter+1,] <- sqrt(sigma_sq_y)
  

  #################################################################
  # Update theta
  theta_proposal <- rnorm(2, mean=mc$theta[mciter,], sd=c(.008,.008))
  Q <- inla.spde2.precision(spde1, theta=mc$theta[mciter,])
  Q_proposal <- inla.spde2.precision(spde1, theta=theta_proposal)
  log_prob_old <- (N-1)*determinant(Q, logarithm=TRUE)$modulus - 
    sum(apply(alpha[,-1]-rho*alpha[,-N]-(1-rho)*mu, 2, 
              function(x) as.numeric(t(x) %*% Q %*% x)))
  log_prob_proposal <- (N-1)*determinant(Q_proposal, logarithm=TRUE)$modulus - 
    sum(apply(alpha[,-1]-rho*alpha[,-N]-(1-rho)*mu, 2, 
              function(x) as.numeric(t(x) %*% Q_proposal %*% x)))
  accept <- exp(log_prob_proposal-log_prob_old)
  c(log_prob_old, log_prob_proposal, accept)
  if( runif(1) < accept){
    mc$theta[mciter+1,] <- theta_proposal
    Q <- Q_proposal
  } else mc$theta[mciter+1,] <- mc$theta[mciter,]

  #plot(colMeans(do.call(cBind,alpha))-)
  print(mciter)
  print(mc$alpha[mciter+1,1,1])


  
}
save(list=ls(), file='mcout.Rdata')
```

```{r plots, eval=FALSE}
theta.df <- data.frame(theta1=mc$theta[-c(1:500),1], theta2=mc$theta[-c(1:500),2]) %>% 
  mutate(logtau=(log(tau0)+theta1), logkappa=(log(kappa0)+theta2)) %>%
  mutate(range= sqrt(8)/exp(logkappa), sigma=1/(sqrt(4*pi)*exp(logtau+logkappa))) %>%
  dplyr::select(range, sigma) 

theta.df %>% summary
plot(theta.df$sigma, type='l')
plot(theta.df$range, type='l')
plot(apply(apply(mc$alpha[-c(1:2500),,],c(1,3), mean),2,mean), type='l')

plot(apply(mc$alpha[4000,,],2, mean), type='l')

library(scales)

spatial.coords %>% mutate(temp=as.vector(A.inst %*% mc$alpha[1000,,51]))
spatial.coords$temp <- as.vector(A.inst %*% mc$alpha[4000,,51])
spatial.coords %>% 
  ggplot() + geom_point(aes(x=lon, y=lat, color=temp)) + 
  scale_color_gradient2(low=muted("blue"), high=muted("red"), midpoint=0, limit=c(-4,4)) + 
  coord_map(projection='mollweide')
spatial.coords %>% mutate(temp=as.vector(A.inst %*% mc$alpha[4000,,163])) %>% 
  ggplot() + geom_tile(aes(x=lon, y=lat, fill=temp)) + 
  scale_fill_gradient2(low=muted("blue"), high=muted("red"), midpoint=0, limit=c(-4,4)) + 
  coord_map(projection='mollweide')


```

